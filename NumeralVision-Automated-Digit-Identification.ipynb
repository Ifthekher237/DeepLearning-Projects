{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd650ce2",
   "metadata": {},
   "source": [
    "## The MNIST Dataset\n",
    "\n",
    "The MNIST dataset comprises 60,000 training images and 10,000 testing images of handwritten digits. These images are in grayscale and have a dimension of 28x28 pixels. In this section, our goal is to create a Feed Forward Neural Network that can effectively categorize these images into the digits 0 to 9.\n",
    "![digit demo](digit_demo.png)\n",
    "\n",
    "In this tutorial, our focus is on creating a feedforward neural network designed to categorize handwritten digits. These images of handwritten digits are part of a well-known dataset known as MNIST, which is highly renowned in the field.\n",
    "\n",
    "Our approach involves flattening the images, essentially transforming them into a one-dimensional format. The number of input neurons in the neural network corresponds to the total number of pixels (28*28 = 784) in each image.\n",
    "\n",
    "For the output layer of our neural network, we have ten neurons. This number aligns with the ten classes we aim to classify because we're dealing with digits ranging from 0 to 9. In essence, our network's purpose is to classify these ten different digits.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b4ab8056",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f91d2b13",
   "metadata": {},
   "source": [
    "We imported ***torchvision.datasets*** for:\n",
    "\n",
    "### Accessing Standard Datasets:\n",
    "***torchvision.datasets*** provides a collection of widely-used standard datasets for computer vision tasks. One of the most famous datasets is the MNIST dataset, which contains images of handwritten digits. Other datasets, like CIFAR-10, CIFAR-100, and ImageNet, are also available. This module makes it easy to access and load these datasets into your project without having to manually download and preprocess the data.\n",
    "\n",
    "### Data Loading and Transformation:\n",
    "The datasets module includes functions and classes to load and preprocess the data. It allows you to apply various transformations to the images, such as resizing, cropping, and data augmentation. This is crucial for preparing the data in a format that's suitable for training deep learning models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1206588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784      # Number of input neurons (image pixels)\n",
    "hidden_size = 400     # Number of hidden neurons\n",
    "out_size = 10         # Number of classes (0-9)\n",
    "epochs = 10           # How many times we pass our entire dataset into our network\n",
    "batch_size = 100      # Input size of the data during one iteration\n",
    "learning_rate = 0.001 # How fast we are learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e744f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(root='./',\n",
    "                              train=True,\n",
    "                              transform=transforms.ToTensor(),\n",
    "                              download=True)\n",
    "\n",
    "test_dataset = datasets.MNIST(root='./',\n",
    "                             train=False,\n",
    "                             transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dba668",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data iterable by loading it to a loader, shuffle the training data to make it independent of the order.\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=False)\n",
    "# when we want to divide our input size into batches, then we need to use train loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60078bb7",
   "metadata": {},
   "source": [
    "![digit neural network](digit_nn.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83ce6b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, out_size):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)   # first layer\n",
    "        self.fc2 = nn.Linear(hidden_size, hidden_size)      # second layer\n",
    "        self.fc3 = nn.Linear(hidden_size, out_size)         # third layer\n",
    "        self.relu = nn.ReLU()                               # activation function\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.fc3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abdfe08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an object of the class, which represents our network\n",
    "net = Net(input_size, hidden_size, out_size) \n",
    "CUDA = torch.cuda.is_available()\n",
    "if CUDA:\n",
    "    #if gpu is available, then switch the network to gpu to work faster\n",
    "    net = net.cuda()\n",
    "    \n",
    "# the loss function. The Corss Entropy loss comes along with softmax. Therefore, no need to specify softmax as well\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d67bae",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# let's see what are inside the net.parameters. \n",
    "net.parameters\n",
    "# list(net.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da34960d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the train loader\n",
    "for i, (images, labels) in enumerate(train_loader):\n",
    "    print(images.size()) \n",
    "    images = images.view(-1, 784) #reshaping the tensor\n",
    "    print(images.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f1beaf",
   "metadata": {},
   "source": [
    "**torch.Size([100, 1, 28, 28])** ==>  100 corresponds to the batch size that we define earlier. So in each iterations, there's 100 images. 1 corresponnds to the number of channels in the image, since we have a grayscaled imaged(not coloured image), if the number of channels in the image is 3 then we have an RGB or colored image. 28 is the height or the number of rows, and the other 28 is the number of columns or the width of the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc2ce36",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Train the network\n",
    "correct_train = 0                                # How many correct classifications our network classifies out of total_train samples\n",
    "total_train = 0\n",
    "for epoch in range(epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # Flatten the image from size (batch,1,28,28) --> (100,1,28,28) where 1 represents the number of channels (grayscale-->1),\n",
    "        # to size (100, 784) and wrap it in a variable\n",
    "        images = Variable(images.view(-1,28*28))\n",
    "        labels = Variable(labels)\n",
    "        \n",
    "        #switching between cpu and gpu\n",
    "        if CUDA:\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "        # clear the param_grad in param <-- param - lr*param_grad, so it won't accumulated\n",
    "        optimizer.zero_grad() \n",
    "        \n",
    "        outputs = net(images)                      # forward pass, \n",
    "        _, predicted = torch.max(outputs.data, 1)  # first argument returns the maximum score and second argument represents the index location of each maximum value found\n",
    "        \n",
    "        total_train += labels.size(0)              # labels.size(0) = 100 (batch_size)\n",
    "        \n",
    "        if CUDA:\n",
    "            # if cuda is available, then all calculations are happening in gpu. so we need to\n",
    "            # transfer these tensors to a cpu because sum() is a python function, there is\n",
    "            # no implementation of sum() on a gpu\n",
    "            correct_train += (predicted.cpu() == labels.cpu()).sum()\n",
    "        else:\n",
    "            # if we don't have cuda\n",
    "            correct_train += (predicted == labels).sum()\n",
    "            \n",
    "        loss = criterion(outputs, labels)           # difference between the actual and predicted(loss function)\n",
    "        loss.backward()                             # Backpropagation\n",
    "        optimizer.step()                            # update the weights\n",
    "        \n",
    "        if (i+1) % 100 == 0:                        # printing the results\n",
    "            print('Epoch [{}/{}], Iteration [{}/{}], Training Loss: {}, Training Accuracy: {}%'.format\n",
    "                  (epoch+1, epochs, i+1, len(train_dataset)//batch_size, loss.item(), (100*correct_train/total_train)))\n",
    "print(\"\\n\\nDONE TRAINING !!\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "809d1cc0",
   "metadata": {},
   "source": [
    "correct_train --> ow many correct classifications our network classifies out of total_train samples. Through every iteration in the loop, the total_train will be incremented by the batch size(100)\n",
    "\n",
    "There are 2 loops:\n",
    " - The outer loop iterates over epochs.\n",
    " - The inner loop iterates over batches of data. Within each epoch, the training dataset is divided into smaller batches, and the inner loop processes these batches one by one. **enumerate(train_loader)** is used to obtain batches of data from the **train_loader**. In each iteration of the inner loop, a batch of images and their corresponding labels are loaded and processed. The neural network is updated with each batch of data using backpropagation and gradient descent.\n",
    "\n",
    "*labels* are 0 to 9\n",
    "\n",
    "The purpose of using **Variable** was to enable automatic differentiation. By wrapping tensors with **Variable**, you signaled to PyTorch that you wanted to track operations on those tensors and compute gradients. This is important because gradients are necessary for updating model parameters during training with gradient-based optimization algorithms like stochastic gradient descent (SGD).\n",
    "\n",
    "However, since PyTorch 0.4 and later versions, automatic differentiation is enabled by default on tensors, which means that you can perform operations on tensors directly, and PyTorch will automatically track those operations and compute gradients. In these newer versions, using Variable for most common use cases is no longer required, and you can work with tensors directly.\n",
    "\n",
    "**outputs**, contains the network's predictions or output for the given input batch of images. After obtaining the network's output (**outputs**), we typically want to determine which class or category the network has predicted for each input and **torch.max(outputs.data, 1)** does that task.\n",
    "**torch.max(outputs.data, 1)** finds the maximum value along dimension 1 (columns) of the outputs tensor. Maximum value basically indicates which label is classified or predicted by the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a245d6e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test the network (We need No loss and weight calculation, no weight update, \n",
    "# just forward propagation is needed)\n",
    "correct = 0\n",
    "total = 0\n",
    "for images, labels in test_loader:\n",
    "    images = Variable(images.view(-1, 28*28))\n",
    "    \n",
    "    if CUDA:\n",
    "        images = images.cuda()\n",
    "    # For each input (or, sample or, row) in the batch, the output will contain 10 elements\n",
    "    outputs = net(images)\n",
    "    # We could also write: predicted = outputs.data.max(1)[1]\n",
    "    _, predicted = torch.max(outputs.data, 1)\n",
    "    total += labels.size(0)         # Increment the total count(100)\n",
    "    # We can also use: correct := predicted.eq(labels).sum()\n",
    "    if CUDA:\n",
    "        correct += (predicted.cpu() == labels.cpu()).sum()\n",
    "    else:\n",
    "        correct += (predicted == labels).sum()\n",
    "        \n",
    "print(\"Final Test Accuracy is : %d %%\" % (100*correct/total))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ffecf2c",
   "metadata": {},
   "source": [
    "In our project, our feedforward neural network has achieved an impressive 97% accuracy on the test dataset, indicating that it doesn't suffer from overfitting and can generalize well to new, unseen data. We plan to explore convolutional neural networks in the next section to investigate the potential for further improvement beyond this already high accuracy. While the current accuracy is commendable, there is still room for enhancement, and we intend to employ techniques like batch normalization and dropout in the upcoming section to potentially push the accuracy even higher. We anticipate that the application of these techniques within the context of convolutional networks will lead to an increase in our final test accuracy, further enhancing the performance of our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df0f39f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb619488",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88d03cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88def1c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de9d94b2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b578324",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d572a376",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8a3e37e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f68f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904670f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c4c7b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "559634c8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
